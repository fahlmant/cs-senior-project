\documentclass{article}

\begin{document}
\title{Lidar Point Clouds and VR}
\author{Joshua Bowen, Taylor Fahlman, Adam Puckette}

\maketitle

\abstract

The goal is to create a virtual-reality application that would allow users of most head-mounted virtual-reality devices to view and manipulate point-cloud data. The solution will draw upon the existing code-base of the OSVR platform and that of the open-source point-cloud visualization software CloudCompare. This will allow for a modular and platform-independent design. This way, anyone with a Head Mounted Display (HMD) will be able to download and view point-cloud data without the 3D TV and specialized hardware needed for previous implementations. In the solution, there will be a GUI which will allow the user to manipulate the point-cloud data from a first-person and third-person perspective. It will also use the Leap Motion's gesture recognition capability to seamlessly respond to user commands.


\section*{Problem Statement}

\section*{Proposed Solution}

To solve the problem presented, the Cloud Compare software and the OSVR framework will be connected. In this way, users of Cloud Compare can then use most VR headsets available to analyze and interact with their data in a 3D virtual reality space. This will allow for the finer control desired for point cloud files. At the expo, a laptop with an attached headset, running the Cloud Compare software and the code connecting it to the OSVR framework will be there. People will be able to put it on and explore a point cloud set, possibly one of the interior of the Kelly Engineering Center. In order to measure performance, there will be different tiers of data points that will need to be rendered well by the headset. For example, the first tier may be rending 100 point of a point cloud, and redering it at a constant rate as the headset moves. The next tier could be 1000 points, and so on. A typical point cloud used by the client can have millions or billions of points. 

\end{document}

